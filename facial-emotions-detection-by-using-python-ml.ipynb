{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"##import modules","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install numpy==1.16.5","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.preprocessing.image import load_img\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\nimport pandas as pd\nimport os\n\n# Rest of your code...\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##loading the dataset","metadata":{}},{"cell_type":"code","source":"##loading the dataset","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TRAIN_DIR = '/kaggle/input/face-expression-recognition-dataset/images/train/'\nVALIDATION_DIR = '/kaggle/input/face-expression-recognition-dataset/images/validation'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def createdataframe(dir):\n    image_paths = []\n    labels = []\n    for label in os.listdir(dir):\n        for imagename in os.listdir(os.path.join(dir,label)):\n            image_paths.append(os.path.join(dir,label,imagename))\n            labels.append(label)\n        print(label, \"completed\")\n    return image_paths,labels","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.DataFrame()\ntrain['image'], train['label'] = createdataframe(TRAIN_DIR)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validation = pd.DataFrame()\nvalidation['image'], validation['label'] = createdataframe(VALIDATION_DIR)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(validation)\nprint(validation['image'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm.notebook import tqdm","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def extract_features(images):\n    features = []\n    for image in tqdm(images):\n        img = load_img(image,color_mode = \"grayscale\" )\n        img = np.array(img)\n        features.append(img)\n    features = np.array(features)\n    features = features.reshape(len(features),48,48,1)\n    return features","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_features = extract_features(train['image']) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validation_features = extract_features(validation['image'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train = train_features/255.0\nx_validation = validation_features/255.0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"le = LabelEncoder()\nle.fit(train['label'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train = le.transform(train['label'])\ny_validation = le.transform(validation['label'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train = to_categorical(y_train,num_classes = 7)\ny_validation = to_categorical(y_validation,num_classes = 7)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\n# convolutional layers\nmodel.add(Conv2D(128, kernel_size=(3,3), activation='relu', input_shape=(48,48,1)))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.4))\n\nmodel.add(Conv2D(256, kernel_size=(3,3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.4))\n\nmodel.add(Conv2D(512, kernel_size=(3,3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.4))\n\nmodel.add(Conv2D(512, kernel_size=(3,3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.4))\n\nmodel.add(Flatten())\n# fully connected layers\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dropout(0.4))\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.3))\n# output layer\nmodel.add(Dense(7, activation='softmax'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = 'accuracy' )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(x= x_train,y = y_train, batch_size = 128, epochs = 100, validation_data = (x_validation,y_validation)) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_json = model.to_json()\nwith open(\"emotiondetector.json\",'w') as json_file:\n    json_file.write(model_json)\nmodel.save(\"emotiondetector.h5\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import model_from_json","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label = ['angry','disgust','fear','happy','neutral','sad','surprise']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def ef(image):\n    img = load_img(image,color_mode = \"grayscale\" )\n    feature = np.array(img)\n    feature = feature.reshape(1,48,48,1)\n    return feature/255.0\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image = '/kaggle/input/face-expression-recognition-dataset/images/train/surprise/10333.jpg'\nprint(\"original image is of surprised\")\nimg = ef(image)\npred = model.predict(img)\npred_label = label[pred.argmax()]\nprint(\"model prediction is \",pred_label)\nplt.imshow(img.reshape(48,48),cmap='gray')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image = '/kaggle/input/face-expression-recognition-dataset/images/train/sad/10008.jpg'\nprint(\"original image is of sad\")\nimg = ef(image)\npred = model.predict(img)\npred_label = label[pred.argmax()]\nprint(\"model prediction is \",pred_label)\nplt.imshow(img.reshape(48,48),cmap='gray')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"image = '/kaggle/input/face-expression-recognition-dataset/images/train/happy/10035.jpg'\nprint(\"original image is of happy\")\nimg = ef(image)\npred = model.predict(img)\npred_label = label[pred.argmax()]\nprint(\"model prediction is \",pred_label)\nplt.imshow(img.reshape(48,48),cmap='gray')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image = '/kaggle/input/face-expression-recognition-dataset/images/train/angry/10142.jpg'\nprint(\"original image is of angry\")\nimg = ef(image)\npred = model.predict(img)\npred_label = label[pred.argmax()]\nprint(\"model prediction is \",pred_label)\nplt.imshow(img.reshape(48,48),cmap='gray')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image = '/kaggle/input/face-expression-recognition-dataset/images/train/fear/10125.jpg'\nprint(\"original image is of fear\")\nimg = ef(image)\npred = model.predict(img)\npred_label = label[pred.argmax()]\nprint(\"model prediction is \",pred_label)\nplt.imshow(img.reshape(48,48),cmap='gray')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image = '/kaggle/input/face-expression-recognition-dataset/images/train/disgust/10606.jpg'\nprint(\"original image is of disgust\")\nimg = ef(image)\npred = model.predict(img)\npred_label = label[pred.argmax()]\nprint(\"model prediction is \",pred_label)\nplt.imshow(img.reshape(48,48),cmap='gray')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image = '/kaggle/input/face-expression-recognition-dataset/images/train/neutral/10119.jpg'\nprint(\"original image is of neutral\")\nimg = ef(image)\npred = model.predict(img)\npred_label = label[pred.argmax()]\nprint(\"model prediction is \",pred_label)\nplt.imshow(img.reshape(48,48),cmap='gray')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##for realtime capture","metadata":{}}]}